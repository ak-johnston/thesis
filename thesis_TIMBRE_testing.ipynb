{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy.linalg as linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "import scipy.io as io\n",
    "import TIMBRE.helpers as helpers\n",
    "import TIMBRE.get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras import models, layers, optimizers, backend, constraints, activations\n",
    "import complexnn\n",
    "import numpy as np\n",
    "from keras import utils as np_utils\n",
    "\n",
    "#redefine TIMBRE function with legacy Adam optimizer so it will run on Mac\n",
    "\n",
    "def TIMBRE(X, Y, inds_test, inds_train, hidden_nodes=0, learn_rate=.001, is_categorical=True, verbosity=0, save_path=None, filename=None):\n",
    "    \"\"\"\n",
    "    Learns oscillatory patterns that are predictive of class labels\n",
    "\n",
    "    Parameters:\n",
    "    - X = Multi-channel data (T samples x N channels, complex-valued)\n",
    "    - Y = Category labels (T samples, integer-valued)\n",
    "    - inds_test = test indices (Either T x 1 boolean, or U x 1 integers)\n",
    "    - inds_train = train indices (Either T x 1 boolean, or U x 1 integers)\n",
    "    - hidden_nodes = how many nodes to use (no hidden layer if set to 0)\n",
    "    - learn_rate = how quickly the network learns\n",
    "    - is_categorical = whether the output consists of discrete classes\n",
    "    - verbosity = amount of model training info to output (default = 0)\n",
    "\n",
    "    Returns:\n",
    "    - model: trained network\n",
    "    - fittedModel: history of loss and accuracy for test and train data\n",
    "    - test_acc: accuracy on test data after training\n",
    "    \"\"\"\n",
    "\n",
    "    # stack the real and imaginary components of the data\n",
    "    X = np.concatenate((np.real(X), np.imag(X)), axis=1)\n",
    "    # use one-hot encoding for the class labels\n",
    "    if is_categorical:\n",
    "        Y = np_utils.to_categorical(Y)\n",
    "        my_loss = 'categorical_crossentropy'\n",
    "    else:\n",
    "        my_loss = 'kde'\n",
    "    backend.clear_session()\n",
    "    # Early Stopping: stop training model when test loss stops decreasing\n",
    "    es = EarlyStopping(monitor='val_loss', patience=1)\n",
    "    # Specify the algorithm and step size used by gradient descent\n",
    "    adam = optimizers.legacy.Adam(learning_rate=learn_rate)\n",
    "    if hidden_nodes > 0:\n",
    "        num_chans = hidden_nodes\n",
    "    else:\n",
    "        num_chans = Y.shape[1]\n",
    "    model = models.Sequential()\n",
    "    # Layer 1: Takes a complex-valued projection of the input\n",
    "    model.add(complexnn.dense.ComplexDense(num_chans, input_shape=(X.shape[1],), use_bias=False,\n",
    "                                           kernel_constraint=constraints.unit_norm()))\n",
    "    # Layer 2: Converts complex-valued output of layer 0 to a real-valued magnitude\n",
    "    model.add(layers.Lambda(lambda x: (x[:, :x.shape[1] // 2] ** 2 + x[:, x.shape[1] // 2:] ** 2) ** .5))\n",
    "    # Layer 3: Softmax of layer 2\n",
    "    model.add(layers.Activation(activations.softmax))\n",
    "    if hidden_nodes > 0:  # Need another layer for output\n",
    "        model.add(layers.Dense(Y.shape[1], activation='softmax'))\n",
    "    model.compile(loss=my_loss, optimizer=adam, metrics=['accuracy'])\n",
    "    # Train the model\n",
    "    fittedModel = model.fit(X[inds_train, :], Y[inds_train, :], epochs=100,\n",
    "                            verbose=0, validation_data=(X[inds_test, :], Y[inds_test, :]),\n",
    "                            shuffle=True, callbacks=[es])\n",
    "    test_acc = fittedModel.history['val_accuracy'][-1]\n",
    "    \n",
    "    #Save trained model (addition from original TIMBRE function)\n",
    "    if filename:\n",
    "        from keras.models import save_model\n",
    "        save_model(model, filename + \".h5\")\n",
    "        \n",
    "    return model, fittedModel, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(matrix, range_low, range_high, btype='bp', fs = 1250/8, order = 3, use_hilbert = True):\n",
    "    #Bandpass filter for specific broadbands \n",
    "    #TIMBRE filter function will not work for bandpass filters!\n",
    "    nyq = 0.5*fs\n",
    "    normal_range_low = range_low / nyq\n",
    "    normal_range_high = range_high / nyq\n",
    "    b, a = signal.butter(order, [normal_range_low, normal_range_high], btype=btype, analog=False)\n",
    "    filt_X = signal.filtfilt(b, a, matrix, axis=0)\n",
    "    return filt_X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_whiten(X, inds_train, u, Xv):\n",
    "    #function to whiten signals using the variance of another signal \n",
    "    #rather than individually calculating variance for each signal\n",
    "    X = X @ np.conj(u.T)\n",
    "    X = X / Xv\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = io.loadmat('data01.mat') #load drudged data to train models, using session 1 as it is the longest \n",
    "lapID = data['lapID']\n",
    "\n",
    "full_LFPs = helpers.filter_data(data['lfps'], 2, fs=1250/8, use_hilbert=True)\n",
    "theta_preHilbert = filter(data['lfps'], range_low = 6, range_high = 12, btype= 'bp',order= 2) \n",
    "harm_preHilbert = filter(data['lfps'], range_low = 14, range_high = 20, btype= 'bp',order= 2)\n",
    "\n",
    "theta_LFPs = signal.hilbert(theta_preHilbert, axis= 0)\n",
    "harm_LFPs = signal.hilbert(harm_preHilbert, axis= 0)\n",
    "double_LFPs = np.abs(theta_LFPs)*np.exp(np.angle(theta_LFPs)*2*1j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_test, inds_train = helpers.test_train(lapID, 1, n_folds=5, which_fold=0)\n",
    "\n",
    "#Whiten signals\n",
    "w_theta, u, Xv = helpers.whiten(theta_LFPs, inds_train)\n",
    "w_harm = band_whiten(harm_LFPs, inds_train, u, Xv)\n",
    "w_double = band_whiten(double_LFPs, inds_train, u, Xv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train TIMBRE on each of the signals\n",
    "theta_model, theta_fittedModel, theta_test_acc = TIMBRE(w_theta, lapID[:,1], inds_test, inds_train, hidden_nodes=48, save_path=\"\", filename=\"theta_model\")\n",
    "harm_model, harm_fittedModel, harm_test_acc = TIMBRE(w_harm, lapID[:,1], inds_test, inds_train, hidden_nodes=48, save_path=\"\", filename=\"harm_model\")\n",
    "double_model, double_fittedModel, double_test_acc = TIMBRE(w_double, lapID[:,1], inds_test, inds_train, hidden_nodes=48, save_path=\"\", filename=\"double_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate data for testing\n",
    "test_theta = np.concatenate((np.real(w_theta), np.imag(w_theta)), axis=1)\n",
    "test_harm = np.concatenate((np.real(w_harm), np.imag(w_harm)), axis=1)\n",
    "test_double = np.concatenate((np.real(w_double), np.imag(w_double)), axis=1)\n",
    "\n",
    "test_Y = np_utils.to_categorical(lapID[:, 1]) #one-hot encode LapID for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate accuracies for each train/test combo\n",
    "trained = ['theta', \"harmonic\", 'doubled']\n",
    "tested = ['theta', \"harmonic\", 'doubled']\n",
    "\n",
    "all_scores = np.zeros((3, 3))\n",
    "\n",
    "trained_models = [theta_model, harm_model, double_model, ]\n",
    "test_data = [test_theta, test_harm, test_double]\n",
    "\n",
    "for i in range(len(trained)):\n",
    "    for j in range(len(tested)):\n",
    "        all_scores[i, j] = trained_models[i].evaluate(test_data[j][inds_test, :], test_Y[inds_test, :])[1]\n",
    "        \n",
    "print(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display accuracies\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(all_scores)\n",
    "\n",
    "# Show all ticks and label them with the respective list entries\n",
    "ax.set_xticks(np.arange(len(tested)), labels=tested)\n",
    "ax.set_yticks(np.arange(len(trained)), labels=trained)\n",
    "ax.set_xlabel('Tested On')\n",
    "ax.set_ylabel('Trained On')\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(len(trained)):\n",
    "    for j in range(len(tested)):\n",
    "        text = ax.text(j, i, str(all_scores[i, j]*100)[:5]+'%',\n",
    "                       ha=\"center\", va=\"center\", color=\"m\")\n",
    "\n",
    "ax.set_title(\"\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolate phase information\n",
    "theta_phases = np.exp(1j*np.angle(theta_LFPs))\n",
    "harm_phases = np.exp(1j*np.angle(harm_LFPs))\n",
    "double_phases = np.exp(1j*np.angle(theta_LFPs)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whiten phase-only signals\n",
    "w_theta_phase, u, Xv = helpers.whiten(theta_LFPs, inds_train)\n",
    "w_harm_phase = band_whiten(harm_LFPs, inds_train, u, Xv)\n",
    "w_double_phase = band_whiten(double_LFPs, inds_train, u, Xv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train TIMBRE on each of the phase only signals\n",
    "theta_phase_model, theta_fittedModel, theta_phase_test_acc = TIMBRE(w_theta_phase, lapID[:,1], inds_test, inds_train, hidden_nodes=48, save_path=\"\", filename=\"theta_phase_model\")\n",
    "harm_phase_model, harm_phase_fittedModel, harm_phase_test_acc = TIMBRE(w_harm_phase, lapID[:,1], inds_test, inds_train, hidden_nodes=48, save_path=\"\", filename=\"harm_phase_model\")\n",
    "double_phase_model, double_phase_fittedModel, double_phase_test_acc = TIMBRE(w_double_phase, lapID[:,1], inds_test, inds_train, hidden_nodes=48, save_path=\"\", filename=\"double_phase_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate phase-only data for testing\n",
    "test_theta_phase = np.concatenate((np.real(w_theta_phase), np.imag(w_theta_phase)), axis=1)\n",
    "test_harm_phase = np.concatenate((np.real(w_harm_phase), np.imag(w_harm_phase)), axis=1)\n",
    "test_double_phase = np.concatenate((np.real(w_double_phase), np.imag(w_double_phase)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate accuracies for each train/test combo\n",
    "trained_phase = ['theta phases', \"harmonic phases\", 'doubled phases']\n",
    "tested_phase = ['theta phases', \"harmonic phases\", 'doubled phases']\n",
    "\n",
    "all_scores_phase = np.zeros((3, 3))\n",
    "\n",
    "trained_phase_models = [theta_phase_model, harm_phase_model, double_phase_model, ]\n",
    "test_data_phase = [test_theta_phase, test_harm_phase, test_double_phase]\n",
    "\n",
    "for i in range(len(trained)):\n",
    "    for j in range(len(tested)):\n",
    "        all_scores[i, j] = trained_phase_models[i].evaluate(test_data_phase[j][inds_test, :], test_Y[inds_test, :])[1]\n",
    "        \n",
    "print(all_scores_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display accuracies for phase-only models\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(all_scores_phase)\n",
    "\n",
    "# Show all ticks and label them with the respective list entries\n",
    "ax.set_xticks(np.arange(len(tested_phase)), labels=tested_phase)\n",
    "ax.set_yticks(np.arange(len(trained_phase)), labels=trained_phase)\n",
    "ax.set_xlabel('Tested On')\n",
    "ax.set_ylabel('Trained On')\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(len(trained_phase)):\n",
    "    for j in range(len(tested_phase)):\n",
    "        text = ax.text(j, i, str(all_scores[i, j]*100)[:5]+'%',\n",
    "                       ha=\"center\", va=\"center\", color=\"m\")\n",
    "\n",
    "ax.set_title(\"\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
